{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3469267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386d2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c73b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197edc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ebbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230362fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "['je suis desole je ne vous ai pas reconnues', 'i m sorry i didn t recognize you']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6879ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d6ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233bc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f16b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebfec3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126d49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab81fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c0c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4295c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce27c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f2436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "1m 28s (- 22m 11s) (5 6%) 1.5582\n",
      "2m 55s (- 20m 26s) (10 12%) 0.7082\n",
      "4m 25s (- 19m 11s) (15 18%) 0.3793\n",
      "5m 53s (- 17m 40s) (20 25%) 0.2160\n",
      "7m 20s (- 16m 10s) (25 31%) 0.1356\n",
      "8m 48s (- 14m 40s) (30 37%) 0.0952\n",
      "10m 16s (- 13m 13s) (35 43%) 0.0724\n",
      "11m 44s (- 11m 44s) (40 50%) 0.0582\n",
      "13m 12s (- 10m 16s) (45 56%) 0.0498\n",
      "14m 43s (- 8m 49s) (50 62%) 0.0451\n",
      "16m 11s (- 7m 21s) (55 68%) 0.0402\n",
      "18m 2s (- 6m 0s) (60 75%) 0.0371\n",
      "19m 24s (- 4m 28s) (65 81%) 0.0352\n",
      "20m 46s (- 2m 58s) (70 87%) 0.0333\n",
      "22m 9s (- 1m 28s) (75 93%) 0.0319\n",
      "23m 29s (- 0m 0s) (80 100%) 0.0302\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d23a36a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il est la pour te proteger\n",
      "= he s here to protect you\n",
      "< he s here to protect you <EOS>\n",
      "\n",
      "> il est plus fort que jamais\n",
      "= he is stronger than ever\n",
      "< he is stronger than ever <EOS>\n",
      "\n",
      "> elle a tres peur des chiens\n",
      "= she s very afraid of dogs\n",
      "< she s very afraid of dogs <EOS>\n",
      "\n",
      "> tu n es qu un etudiant\n",
      "= you are nothing but a student\n",
      "< you are nothing but a student <EOS>\n",
      "\n",
      "> je suis un peu emeche\n",
      "= i m a bit tipsy\n",
      "< i m a bit tipsy <EOS>\n",
      "\n",
      "> je suis la seule a avoir survecu\n",
      "= i m the only one who survived\n",
      "< i m the only one who survived <EOS>\n",
      "\n",
      "> je suis beaucoup plus jeune que vous\n",
      "= i m much younger than you\n",
      "< i m much younger than you <EOS>\n",
      "\n",
      "> il n est pas gentil avec elle\n",
      "= he is not kind to her\n",
      "< he is not kind to her <EOS>\n",
      "\n",
      "> elle ne convient pas a la tache\n",
      "= she isn t adequate to the task\n",
      "< she isn t adequate to the task <EOS>\n",
      "\n",
      "> il est competent en espagnol et en italien\n",
      "= he is proficient in both spanish and italian\n",
      "< he is proficient of our and sort of biology <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77e10fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = il n est pas aussi grand que son pere\n",
      "output = he is not as tall as his father <EOS>\n",
      "input = je suis trop fatigue pour conduire\n",
      "output = i m too tired to drive now <EOS>\n",
      "input = je suis desole si c est une question idiote\n",
      "output = i m sorry if this is a stupid question <EOS>\n",
      "input = je suis reellement fiere de vous\n",
      "output = i m really proud of you <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_12364\\1690937169.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_12364\\1690937169.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_12364\\1690937169.py:16: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74ff43",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3b29c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import gensim.downloader as api\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDING_DIM = 300  # GloVe dimension\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "MAX_LENGTH = 25\n",
    "LOAD_PRETRAINED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8afdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and preprocess data\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, parquet_path):\n",
    "        self.df = pd.read_parquet(parquet_path)\n",
    "        self.questions, self.answers = self.preprocess_data()\n",
    "        \n",
    "        # Build vocabularies\n",
    "        self.question_vocab = self.build_vocab(self.questions)\n",
    "        self.answer_vocab = self.build_vocab(self.answers)\n",
    "        \n",
    "        # Load pretrained embeddings using Gensim\n",
    "        self.glove = api.load(\"glove-wiki-gigaword-300\") if LOAD_PRETRAINED else None\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        def normalize_text(text):\n",
    "            text = text.lower().strip()\n",
    "            text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "            text = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", text)\n",
    "            return text\n",
    "            \n",
    "        questions = [normalize_text(q) for q in self.df['question']]\n",
    "        answers = [normalize_text(a) for a in self.df['answer']]\n",
    "        return questions, answers\n",
    "    \n",
    "    def build_vocab(self, sentences):\n",
    "        word_counts = Counter()\n",
    "        for sentence in sentences:\n",
    "            word_counts.update(sentence.split())\n",
    "        \n",
    "        vocab = {\n",
    "            'word2idx': {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3},\n",
    "            'idx2word': {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
    "        }\n",
    "        \n",
    "        idx = 4\n",
    "        for word, count in word_counts.items():\n",
    "            if count >= 2:  # Only keep words appearing at least twice\n",
    "                vocab['word2idx'][word] = idx\n",
    "                vocab['idx2word'][idx] = word\n",
    "                idx += 1\n",
    "                \n",
    "        return vocab\n",
    "    \n",
    "    def sentence_to_tensor(self, sentence, vocab):\n",
    "        indexes = [vocab['word2idx'].get(word, 3) for word in sentence.split()]\n",
    "        indexes = [1] + indexes + [2]  # Add SOS and EOS\n",
    "        return torch.tensor(indexes, dtype=torch.long)\n",
    "    \n",
    "    def create_emb_layer(self, vocab_size):\n",
    "        emb_layer = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "        if LOAD_PRETRAINED and self.glove is not None:\n",
    "            for word, idx in self.question_vocab['word2idx'].items():\n",
    "                if word in self.glove:\n",
    "                    emb_layer.weight.data[idx] = torch.from_numpy(self.glove[word])\n",
    "                else:\n",
    "                    emb_layer.weight.data[idx] = torch.randn(EMBEDDING_DIM) * 0.25\n",
    "        return emb_layer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question_tensor = self.sentence_to_tensor(self.questions[idx], self.question_vocab)\n",
    "        answer_tensor = self.sentence_to_tensor(self.answers[idx], self.answer_vocab)\n",
    "        return question_tensor, answer_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc2d69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enhanced Encoder with Pretrained Embeddings\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = self.create_emb_layer(vocab_size)\n",
    "        self.gru = nn.GRU(EMBEDDING_DIM, hidden_size, num_layers=num_layers,\n",
    "                         dropout=dropout if num_layers>1 else 0, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def create_emb_layer(self, vocab_size):\n",
    "        emb_layer = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "        if LOAD_PRETRAINED:\n",
    "            weights = np.zeros((len(qa_dataset.question_vocab['word2idx']), EMBEDDING_DIM))\n",
    "            for word, idx in qa_dataset.question_vocab['word2idx'].items():\n",
    "                if word in qa_dataset.glove.stoi:\n",
    "                    weights[idx] = qa_dataset.glove.vectors[qa_dataset.glove.stoi[word]]\n",
    "                else:\n",
    "                    weights[idx] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "            emb_layer.load_state_dict({'weight': torch.from_numpy(weights)})\n",
    "        return emb_layer\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d51e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Enhanced Decoder with Attention\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "        self.attention = nn.Linear(hidden_size + EMBEDDING_DIM, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + EMBEDDING_DIM, hidden_size, num_layers=num_layers,\n",
    "                         dropout=dropout if num_layers>1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size*2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attn_weights = F.softmax(self.attention(torch.cat((embedded, hidden), dim=1), dim=1))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs.permute(1,0,2))\n",
    "        gru_input = torch.cat((embedded, attn_applied.squeeze(1)), dim=1)\n",
    "        output, hidden = self.gru(gru_input.unsqueeze(0), hidden.unsqueeze(0))\n",
    "        prediction = self.fc(torch.cat((output.squeeze(0), attn_applied.squeeze(1)), dim=1))\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7462e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training Setup\n",
    "def collate_batch(batch):\n",
    "    questions, answers = zip(*batch)\n",
    "    questions_pad = pad_sequence(questions, padding_value=0)\n",
    "    answers_pad = pad_sequence(answers, padding_value=0)\n",
    "    return questions_pad.to(device), answers_pad.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbb60f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset and dataloader\n",
    "qa_dataset = QADataset('Question_Answer.parquet')\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec6b4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "encoder = Encoder(len(qa_dataset.question_vocab['word2idx']), HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(device)\n",
    "decoder = Decoder(len(qa_dataset.answer_vocab['word2idx']), HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cc432af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training Loop with Gradient Clipping\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    encoder, decoder = model\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, trg in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        encoder_outputs, hidden = encoder(src)\n",
    "        decoder_input = trg[0,:]\n",
    "        loss = 0\n",
    "        \n",
    "        for t in range(1, trg.shape[0]):\n",
    "            predictions, hidden = decoder(decoder_input, hidden, encoder_outputs)\n",
    "            loss += criterion(predictions, trg[t])\n",
    "            decoder_input = trg[t] if random.random() < 0.5 else predictions.argmax(1)\n",
    "            \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() / trg.shape[0]\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "166d5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation\n",
    "def answer_question(question, encoder, decoder, dataset):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        question_tensor = dataset.sentence_to_tensor(question, dataset.question_vocab).unsqueeze(1).to(device)\n",
    "        encoder_outputs, hidden = encoder(question_tensor)\n",
    "        \n",
    "        answer = []\n",
    "        decoder_input = torch.tensor([1], device=device)  # SOS token\n",
    "        \n",
    "        for _ in range(MAX_LENGTH):\n",
    "            predictions, hidden = decoder(decoder_input, hidden, encoder_outputs)\n",
    "            top_idx = predictions.argmax(1).item()\n",
    "            \n",
    "            if top_idx == 2:  # EOS token\n",
    "                break\n",
    "                \n",
    "            answer.append(dataset.answer_vocab['idx2word'].get(top_idx, '<UNK>'))\n",
    "            decoder_input = torch.tensor([top_idx], device=device)\n",
    "            \n",
    "        return ' '.join(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

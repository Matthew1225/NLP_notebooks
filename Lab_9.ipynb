{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39c9a1c",
   "metadata": {},
   "source": [
    "### Examples from lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c79d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48efe8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.test.utils\n",
    "\n",
    "# Set file names for train and test data\n",
    "lee_train_file = gensim.test.utils.datapath('lee_background.cor')\n",
    "lee_test_file = gensim.test.utils.datapath('lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dcc40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['the', 'national', 'road', 'toll', 'for', 'the', 'christmas', 'new', 'year', 'holiday', 'period', 'stands', 'at', 'eight', 'fewer', 'than', 'for', 'the', 'same', 'time', 'last', 'year', 'people', 'have', 'died', 'on', 'new', 'south', 'wales', 'roads', 'with', 'eight', 'fatalities', 'in', 'both', 'queensland', 'and', 'victoria', 'western', 'australia', 'the', 'northern', 'territory', 'and', 'south', 'australia', 'have', 'each', 'recorded', 'three', 'deaths', 'while', 'the', 'act', 'and', 'tasmania', 'remain', 'fatality', 'free'], [2]>\n",
      "['the', 'united', 'states', 'government', 'has', 'said', 'it', 'wants', 'to', 'see', 'president', 'robert', 'mugabe', 'removed', 'from', 'power', 'and', 'that', 'it', 'is', 'working', 'with', 'the', 'zimbabwean', 'opposition', 'to', 'bring', 'about', 'change', 'of', 'administration', 'as', 'scores', 'of', 'white', 'farmers', 'went', 'into', 'hiding', 'to', 'escape', 'round', 'up', 'by', 'zimbabwean', 'police', 'senior', 'bush', 'administration', 'official', 'called', 'mr', 'mugabe', 'rule', 'illegitimate', 'and', 'irrational', 'and', 'said', 'that', 'his', 're', 'election', 'as', 'president', 'in', 'march', 'was', 'won', 'through', 'fraud', 'walter', 'kansteiner', 'the', 'assistant', 'secretary', 'of', 'state', 'for', 'african', 'affairs', 'went', 'on', 'to', 'blame', 'mr', 'mugabe', 'policies', 'for', 'contributing', 'to', 'the', 'threat', 'of', 'famine', 'in', 'zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))\n",
    "\n",
    "print(train_corpus[2])\n",
    "print(test_corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7abfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0849c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f3673a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x16dfa28b430>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7a7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14180753 -0.16909318 -0.2134914   0.13927513  0.04091355  0.02493528\n",
      "  0.11452319  0.02688671 -0.26071814 -0.04064682  0.13835856  0.01400604\n",
      " -0.12504312 -0.0316937  -0.24284218 -0.14089742  0.0889559   0.10072058\n",
      "  0.07568635 -0.05603003 -0.03883033 -0.04430138  0.30717254  0.06925573\n",
      "  0.02079284 -0.10423418 -0.15538014 -0.16209278 -0.08465276 -0.05523092\n",
      "  0.34479874 -0.10655043  0.2604831   0.08165478  0.13442086  0.11057539\n",
      " -0.12086464 -0.12361484 -0.04350721  0.03735721  0.11372878  0.02081445\n",
      "  0.03745525 -0.12531903  0.15474778  0.11547173 -0.0996522  -0.18026035\n",
      "  0.11184353  0.03305049]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['Only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b525a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 292, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2a7d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (23): «china said sunday it issued new regulations controlling the export of missile technology taking steps to ease concerns about transferring sensitive equipment to middle east countries particularly iran however the new rules apparently do not ban outright the transfer of specific items something washington long has urged beijing to do»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (234, 0.6025307178497314): «the foreign minister alexander downer has expressed concern about man who was arrested in india and has reportedly confessed to planning suicide attacks in australia the man was arrested month ago in india on suspicion of links to osama bin laden al qaeda network india home minister lk advani has been quoted by the reuters news agency as telling meeting of business and industry leaders in new delhi that the man has confessed to planning suicide attacks in australia and britain as well as on the indian parliament the report says mr advani says indian authorities have confirmed and verified the confessions mr downer has told channel seven it should not be dismissed understand that his claim that he wanted to conduct suicide attacks against number of countries including australia is claim that he believes mr downer said don think this is hoax or should be treated as hoax think these are claims that need to be taken seriously we can be grateful for the fact that he has been arrested by indian authorities»\n",
      "\n",
      "MEDIAN (130, 0.30565887689590454): «the condition of former indonesian dictator suharto has improved day after the year old former ruler was put on an intravenous drip and given oxygen to assist his breathing doctors performed series of tests early today and said suharto condition had picked up slightly since yesterday he is still attached to an iv drip but the doctors said bapak father condition is much better than yesterday staff member told afp on the condition of anonymity the doctors are still talking to his children he said suharto fell ill on sunday when he and his family received some visitors including ex ministers and former vice presidents at his family house for celebrations to mark the muslim festival of eid al fitr the former president ruled indonesia for years before he was forced from office in he has been fitted with pacemaker and suffered at least one slight stroke as well as periodic breathing and urinary complications he underwent an emergency appendectomy on february this year the staff said doctors had planned on hospitalising suharto on sunday but monday test result showed he could be treated at home his breathing rhythm is normal and unlike yesterday he does not required an oxygen mask the staff member added suharto has been charged with embezzlling trillion rupiah aud billion of public funds during his time in office but he has repeatedly failed to appear in court to answer the charges with his lawyers arguing that he is too ill to stand trial»\n",
      "\n",
      "LEAST (157, -0.009746822528541088): «british man has been found guilty by unanimous verdict of the kidnap and murder of an eight year old schoolgirl whose death in july shocked britain and set off rampage of anti paedophile vigilantes roy whiting was sentenced to life imprisonment for the abduction and murder of eight year old sarah payne with recommendation by trial judge justice richard curtis that he never be released you are indeed an evil man you are in no way mentally unwell have seen you for month and in my view you are glib and cunning liar justice curtis said there were cheers of delight as the verdicts were read out by the foreman at lewes crown court the jury of nine men and three women had been deliberating for nine hours as soon as the verdicts were declared the court heard details of whiting previous conviction for the kidnap and indecent assault of nine year old girl in prosecutor timothy langdale told the jury how the defendant threw the child into the back of his dirty red ford sierra and locked the doors he had driven her somewhere she didn know where when she asked where they were going he said shut up because he had knife mr langdale said the defendant told the girl to take off her clothes when she refused he produced rope from his pocket and threatened to tie her up what he actually threatened was that he would tie her mouth up she took her clothes off as he had ordered her to do mr langdale then gave graphic details of the abuse to which whiting subjected the terrified child whiting was given four year jail sentence in june after admitting carrying out the attack in march that year but he was released in november despite warnings from probation officers who were convinced there was danger he would attack another child they set out their warnings in pre sentence report prepared after the first assault and in the parole report before he was released from prison he was kept under supervision for four months after his release but was not being monitored by july last year when eight year old sarah was abducted and killed whiting has been arrested three times in connection with the case but the first and second times was released without being charged sarah disappeared on july last year prompting massive police search her partially buried naked body was found days later in field and police believe she was strangled or suffocated»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a6a6c",
   "metadata": {},
   "source": [
    "### Task 0:\n",
    " Train your own doc2vec model on a test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d625618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (1.26.0)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.10.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2024.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\matthew\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2024.11.0-cp310-cp310-win_amd64.whl (670 kB)\n",
      "   ---------------------------------------- 0.0/670.7 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 262.1/670.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 670.7/670.7 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.10.0-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.10.0 fastparquet-2024.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93d0f76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107644</th>\n",
       "      <td>107644</td>\n",
       "      <td>107644.0</td>\n",
       "      <td>SVD Perspectives for Augmenting DeepONet Flexi...</td>\n",
       "      <td>Deep operator networks (DeepONets) are power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>33964</td>\n",
       "      <td>33964.0</td>\n",
       "      <td>Towards robust audio spoofing detection: a det...</td>\n",
       "      <td>Automatic speaker verification, like every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>3137</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>Guided Random Forest in the RRF Package</td>\n",
       "      <td>Random Forest (RF) is a powerful supervised ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33168</th>\n",
       "      <td>33168</td>\n",
       "      <td>33168.0</td>\n",
       "      <td>Best Arm Identification in Generalized Linear ...</td>\n",
       "      <td>Motivated by drug design, we consider the be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20962</th>\n",
       "      <td>20962</td>\n",
       "      <td>20962.0</td>\n",
       "      <td>Conditional Affordance Learning for Driving in...</td>\n",
       "      <td>Most existing approaches to autonomous drivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96969</th>\n",
       "      <td>96969</td>\n",
       "      <td>96969.0</td>\n",
       "      <td>Empirical evaluation of shallow and deep learn...</td>\n",
       "      <td>This work presents a detailed comparison of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73593</th>\n",
       "      <td>73593</td>\n",
       "      <td>73593.0</td>\n",
       "      <td>Safe and Efficient Model-free Adaptive Control...</td>\n",
       "      <td>Adaptive control approaches yield high-perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60738</th>\n",
       "      <td>60738</td>\n",
       "      <td>60738.0</td>\n",
       "      <td>Evaluating Community Detection Algorithms for ...</td>\n",
       "      <td>Many algorithms have been proposed in the la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101781</th>\n",
       "      <td>101781</td>\n",
       "      <td>101781.0</td>\n",
       "      <td>On Almost Sure Convergence Rates of Stochastic...</td>\n",
       "      <td>The vast majority of convergence rates analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70266</th>\n",
       "      <td>70266</td>\n",
       "      <td>70266.0</td>\n",
       "      <td>Truly shift-invariant convolutional neural net...</td>\n",
       "      <td>Thanks to the use of convolution and pooling...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  \\\n",
       "107644        107644    107644.0   \n",
       "33964          33964     33964.0   \n",
       "3137            3137      3137.0   \n",
       "33168          33168     33168.0   \n",
       "20962          20962     20962.0   \n",
       "...              ...         ...   \n",
       "96969          96969     96969.0   \n",
       "73593          73593     73593.0   \n",
       "60738          60738     60738.0   \n",
       "101781        101781    101781.0   \n",
       "70266          70266     70266.0   \n",
       "\n",
       "                                                    title  \\\n",
       "107644  SVD Perspectives for Augmenting DeepONet Flexi...   \n",
       "33964   Towards robust audio spoofing detection: a det...   \n",
       "3137              Guided Random Forest in the RRF Package   \n",
       "33168   Best Arm Identification in Generalized Linear ...   \n",
       "20962   Conditional Affordance Learning for Driving in...   \n",
       "...                                                   ...   \n",
       "96969   Empirical evaluation of shallow and deep learn...   \n",
       "73593   Safe and Efficient Model-free Adaptive Control...   \n",
       "60738   Evaluating Community Detection Algorithms for ...   \n",
       "101781  On Almost Sure Convergence Rates of Stochastic...   \n",
       "70266   Truly shift-invariant convolutional neural net...   \n",
       "\n",
       "                                                 abstract  \n",
       "107644    Deep operator networks (DeepONets) are power...  \n",
       "33964     Automatic speaker verification, like every o...  \n",
       "3137      Random Forest (RF) is a powerful supervised ...  \n",
       "33168     Motivated by drug design, we consider the be...  \n",
       "20962     Most existing approaches to autonomous drivi...  \n",
       "...                                                   ...  \n",
       "96969     This work presents a detailed comparison of ...  \n",
       "73593     Adaptive control approaches yield high-perfo...  \n",
       "60738     Many algorithms have been proposed in the la...  \n",
       "101781    The vast majority of convergence rates analy...  \n",
       "70266     Thanks to the use of convolution and pooling...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('../ML-Arxiv-papers.parquet').sample(n=1000, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae67564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['guided', 'random', 'forest', 'in', 'the', 'rrf', 'package', 'random', 'forest', 'rf', 'is', 'powerful', 'supervised', 'learner', 'and', 'has', 'been', 'popularly', 'used', 'in', 'many', 'applications', 'such', 'as', 'bioinformatics', 'in', 'this', 'work', 'we', 'propose', 'the', 'guided', 'random', 'forest', 'grf', 'for', 'feature', 'selection', 'similar', 'to', 'feature', 'selection', 'method', 'called', 'guided', 'regularized', 'random', 'forest', 'grrf', 'grf', 'is', 'built', 'using', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'rf', 'however', 'the', 'trees', 'in', 'grrf', 'are', 'built', 'sequentially', 'are', 'highly', 'correlated', 'and', 'do', 'not', 'allow', 'for', 'parallel', 'computing', 'while', 'the', 'trees', 'in', 'grf', 'are', 'built', 'independently', 'and', 'can', 'be', 'implemented', 'in', 'parallel', 'experiments', 'on', 'high', 'dimensional', 'gene', 'data', 'sets', 'show', 'that', 'with', 'fixed', 'parameter', 'value', 'without', 'tuning', 'the', 'parameter', 'rf', 'applied', 'to', 'features', 'selected', 'by', 'grf', 'outperforms', 'rf', 'applied', 'to', 'all', 'features', 'on', 'data', 'sets', 'and', 'of', 'them', 'have', 'significant', 'differences', 'at', 'the', 'level', 'therefore', 'both', 'accuracy', 'and', 'are', 'significantly', 'improved', 'grf', 'selects', 'more', 'features', 'than', 'grrf', 'however', 'leads', 'to', 'better', 'classification', 'accuracy', 'note', 'in', 'this', 'work', 'the', 'guided', 'random', 'forest', 'is', 'guided', 'by', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'random', 'forest', 'however', 'it', 'can', 'also', 'be', 'guided', 'by', 'other', 'methods', 'such', 'as', 'human', 'insights', 'by', 'specifying', 'lambda_i', 'grf', 'can', 'be', 'used', 'in', 'rrf', 'and', 'later', 'versions', 'package', 'that', 'also', 'includes', 'the', 'regularized', 'random', 'forest', 'methods'], [2]>\n",
      "['guided', 'random', 'forest', 'in', 'the', 'rrf', 'package', 'random', 'forest', 'rf', 'is', 'powerful', 'supervised', 'learner', 'and', 'has', 'been', 'popularly', 'used', 'in', 'many', 'applications', 'such', 'as', 'bioinformatics', 'in', 'this', 'work', 'we', 'propose', 'the', 'guided', 'random', 'forest', 'grf', 'for', 'feature', 'selection', 'similar', 'to', 'feature', 'selection', 'method', 'called', 'guided', 'regularized', 'random', 'forest', 'grrf', 'grf', 'is', 'built', 'using', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'rf', 'however', 'the', 'trees', 'in', 'grrf', 'are', 'built', 'sequentially', 'are', 'highly', 'correlated', 'and', 'do', 'not', 'allow', 'for', 'parallel', 'computing', 'while', 'the', 'trees', 'in', 'grf', 'are', 'built', 'independently', 'and', 'can', 'be', 'implemented', 'in', 'parallel', 'experiments', 'on', 'high', 'dimensional', 'gene', 'data', 'sets', 'show', 'that', 'with', 'fixed', 'parameter', 'value', 'without', 'tuning', 'the', 'parameter', 'rf', 'applied', 'to', 'features', 'selected', 'by', 'grf', 'outperforms', 'rf', 'applied', 'to', 'all', 'features', 'on', 'data', 'sets', 'and', 'of', 'them', 'have', 'significant', 'differences', 'at', 'the', 'level', 'therefore', 'both', 'accuracy', 'and', 'are', 'significantly', 'improved', 'grf', 'selects', 'more', 'features', 'than', 'grrf', 'however', 'leads', 'to', 'better', 'classification', 'accuracy', 'note', 'in', 'this', 'work', 'the', 'guided', 'random', 'forest', 'is', 'guided', 'by', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'random', 'forest', 'however', 'it', 'can', 'also', 'be', 'guided', 'by', 'other', 'methods', 'such', 'as', 'human', 'insights', 'by', 'specifying', 'lambda_i', 'grf', 'can', 'be', 'used', 'in', 'rrf', 'and', 'later', 'versions', 'package', 'that', 'also', 'includes', 'the', 'regularized', 'random', 'forest', 'methods']\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = (df[\"title\"].fillna('') + \" \" + df[\"abstract\"].fillna('')).str.strip()\n",
    "\n",
    "\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "def preprocess_parquet(texts, tokens_only=False):\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "\n",
    "train_corpus = list(preprocess_parquet(texts))\n",
    "test_corpus = list(preprocess_parquet(texts, tokens_only=True))  \n",
    "\n",
    "print(train_corpus[2])\n",
    "print(test_corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77ef5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ba75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdf35cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0de2598a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x16e88337a60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738de4b4",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "Assess validity of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a754e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16167223 -0.02172993  0.36377457 -0.2545349   0.3722068  -0.05069159\n",
      "  0.11265036  0.24334888 -0.06294134 -0.0856095  -0.03224462 -0.37202698\n",
      "  0.02632106 -0.25605708 -0.3394354   0.17249615  0.6947334   0.2674203\n",
      "  0.36855903 -0.09802157 -0.1925795  -0.06018624 -0.20520961 -0.00561531\n",
      " -0.07535204 -0.20329171 -0.10838228  0.495497   -0.2315021  -0.11959247\n",
      " -0.01214309 -0.01285821  0.15958141 -0.10533137 -0.0127889  -0.61267513\n",
      "  0.42985138 -0.08009687  0.03431808  0.22098233  0.44000176  0.2897394\n",
      " -0.40465808 -0.61617213  0.56965774 -0.28481513  0.15177488  0.10003507\n",
      "  0.00301846  0.42797667]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98c3a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4f8abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (963): «max margin deep generative models deep generative models dgms are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability however little work has been done on examining or empowering the discriminative ability of dgms on making accurate predictions this paper presents max margin deep generative models mmdgms which explore the strongly discriminative principle of max margin learning to improve the discriminative power of dgms while retaining the generative capability we develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objective empirical results on mnist and svhn datasets demonstrate that max margin learning can significantly improve the prediction performance of dgms and meanwhile retain the generative ability and mmdgms are competitive to the state of the art fully discriminative networks by employing deep convolutional neural networks cnns as both recognition and generative models»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (963, 0.9619103670120239): «max margin deep generative models deep generative models dgms are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability however little work has been done on examining or empowering the discriminative ability of dgms on making accurate predictions this paper presents max margin deep generative models mmdgms which explore the strongly discriminative principle of max margin learning to improve the discriminative power of dgms while retaining the generative capability we develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objective empirical results on mnist and svhn datasets demonstrate that max margin learning can significantly improve the prediction performance of dgms and meanwhile retain the generative ability and mmdgms are competitive to the state of the art fully discriminative networks by employing deep convolutional neural networks cnns as both recognition and generative models»\n",
      "\n",
      "MEDIAN (598, 0.23494641482830048): «exploring the distributed knowledge congruence in proxy data free federated distillation federated learning fl is distributed machine learning paradigm in which the server periodically aggregates local model parameters from clients without assembling their private data constrained communication and personalization requirements pose severe challenges to fl federated distillation fd is proposed to simultaneously address the above two problems which exchanges knowledge between the server and clients supporting heterogeneous local models while significantly reducing communication overhead however most existing fd methods require proxy dataset which is often unavailable in reality few recent proxy data free fd approaches can eliminate the need for additional public data but suffer from remarkable discrepancy among local knowledge due to model heterogeneity leading to ambiguous representation on the server and inevitable accuracy degradation to tackle this issue we propose proxy data free fd algorithm based on distributed knowledge congruence feddkc feddkc leverages well designed refinement strategies to narrow local knowledge differences into an acceptable upper bound so as to mitigate the negative effects of knowledge incongruence specifically from perspectives of peak probability and shannon entropy of local knowledge we design kernel based knowledge refinement kkr and searching based knowledge refinement skr respectively and theoretically guarantee that the refined local knowledge can satisfy an approximately similar distribution and be regarded as congruent extensive experiments conducted on three common datasets demonstrate that our proposed feddkc significantly outperforms the state of the art accuracy boosts in comparisons top accuracy boosts by up to and top accuracy boosts by up to on various heterogeneous settings while evidently improving the convergence speed»\n",
      "\n",
      "LEAST (657, -0.29819753766059875): «contextual user browsing bandits for large scale online mobile recommendation online recommendation services recommend multiple commodities to users nowadays considerable proportion of users visit commerce platforms by mobile devices due to the limited screen size of mobile devices positions of items have significant influence on clicks higher positions lead to more clicks for one commodity the pseudo exposure issue only few recommended items are shown at first glance and users need to slide the screen to browse other items therefore some recommended items ranked behind are not viewed by users and it is not proper to treat this kind of items as negative samples while many works model the online recommendation as contextual bandit problems they rarely take the influence of positions into consideration and thus the estimation of the reward function may be biased in this paper we aim at addressing these two issues to improve the performance of online mobile recommendation our contributions are four fold first since we concern the reward of set of recommended items we model the online recommendation as contextual combinatorial bandit problem and define the reward of recommended set second we propose novel contextual combinatorial bandit method called ubm linucb to address two issues related to positions by adopting the user browsing model ubm click model for web search third we provide formal regret analysis and prove that our algorithm achieves sublinear regret independent of the number of items finally we evaluate our algorithm on two real world datasets by novel unbiased estimator an online experiment is also implemented in taobao one of the most popular commerce platforms in the world results on two ctr metrics show that our algorithm outperforms the other contextual bandit algorithms»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
